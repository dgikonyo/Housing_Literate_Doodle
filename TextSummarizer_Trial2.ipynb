{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextSummarizer_Trial2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E17HnbWC_AvQ"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from pickle import dump, load\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twLrazxXv16P",
        "outputId": "5d529267-aa4d-4305-8cfd-38ad9e95a01a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNoTRAWi_NXt"
      },
      "source": [
        "reviews_file=pd.read_csv('/content/drive/MyDrive/school/DataSets/archive/Reviews.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrNKrUSMgHyV"
      },
      "source": [
        "reviews=reviews_file.iloc[:200]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc3pjoKz14MJ",
        "outputId": "d61959e1-1772-4d02-9015-5f864ee48ca6"
      },
      "source": [
        "type(reviews)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z37HvSd__mQ9",
        "outputId": "1ebda0a9-d2db-413e-ca4d-b832e05f2683"
      },
      "source": [
        "type(reviews)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "XnBvXV-V_xT2",
        "outputId": "32e4c813-ac8a-4893-f846-d219ede9a2a4"
      },
      "source": [
        "reviews.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4ZM2ia-_3-E",
        "outputId": "24a32c10-f452-4104-9ca5-386200029529"
      },
      "source": [
        "reviews.isnull().sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Id                        0\n",
              "ProductId                 0\n",
              "UserId                    0\n",
              "ProfileName               0\n",
              "HelpfulnessNumerator      0\n",
              "HelpfulnessDenominator    0\n",
              "Score                     0\n",
              "Time                      0\n",
              "Summary                   0\n",
              "Text                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL3iZ_sJAAPj"
      },
      "source": [
        "**Remove Null values and Features we don't need**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "Oir98VvvAGOU",
        "outputId": "ac229554-1302-48cf-ffc2-b54308a24de9"
      },
      "source": [
        "reviews=reviews.dropna()\n",
        "reviews.drop(['Id','ProductId','UserId', 'ProfileName', 'HelpfulnessNumerator','HelpfulnessDenominator','Score','Time'],1)#using '1' as an axis means we want to drop columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>Altoids mini mints tins</td>\n",
              "      <td>These little tins of sugar free mine mints wer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>Altoids Smalls-Wintergreen</td>\n",
              "      <td>Pros:&lt;br /&gt;+packaging, shipping, price&lt;br /&gt;+s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>Sugarfree...</td>\n",
              "      <td>Be careful not to eat too many of them in one ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Tasty!!</td>\n",
              "      <td>These mints are really strong and have a great...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>These mints are awesome!</td>\n",
              "      <td>This is a huge supply of them. I'm still worki...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Summary                                               Text\n",
              "0         Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
              "1             Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2         \"Delight\" says it all  This is a confection that has been around a fe...\n",
              "3                Cough Medicine  If you are looking for the secret ingredient i...\n",
              "4                   Great taffy  Great taffy at a great price.  There was a wid...\n",
              "..                          ...                                                ...\n",
              "195     Altoids mini mints tins  These little tins of sugar free mine mints wer...\n",
              "196  Altoids Smalls-Wintergreen  Pros:<br />+packaging, shipping, price<br />+s...\n",
              "197                Sugarfree...  Be careful not to eat too many of them in one ...\n",
              "198                     Tasty!!  These mints are really strong and have a great...\n",
              "199    These mints are awesome!  This is a huge supply of them. I'm still worki...\n",
              "\n",
              "[200 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "Z6JIHkk6BH2P",
        "outputId": "9ce68e4f-91cc-4f45-f567-b75957026faa"
      },
      "source": [
        "reviews = reviews.reset_index(drop=True)\n",
        "reviews.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbzO54c_SjnM",
        "outputId": "c92f3fdf-334d-41cc-8c7c-484577e7da59"
      },
      "source": [
        "for i in range(5):\n",
        "  print(\"Review #\",i+1)\n",
        "  print(reviews.Summary[i])\n",
        "  print(reviews.Text[i])\n",
        "  print()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review # 1\n",
            "Good Quality Dog Food\n",
            "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
            "\n",
            "Review # 2\n",
            "Not as Advertised\n",
            "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
            "\n",
            "Review # 3\n",
            "\"Delight\" says it all\n",
            "This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n",
            "\n",
            "Review # 4\n",
            "Cough Medicine\n",
            "If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n",
            "\n",
            "Review # 5\n",
            "Great taffy\n",
            "Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twnf9C5JTBOD"
      },
      "source": [
        "**Replace contractions with their longer forms** \n",
        "A contraction is the combination of two words into a reduced form, with the omission of some internal letters and the use of an apostrophe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdJQtI9OS_oF"
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0DSaY95Tiu2"
      },
      "source": [
        "**Clean the text documents by replacing contractions and removing stop words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFkyNHD2ThQt"
      },
      "source": [
        "def clean_text(text, remove_stopwords=True):\n",
        "  # convert the words into lower case\n",
        "  text= text.lower()\n",
        "\n",
        "  if True:\n",
        "    text=text.split()\n",
        "    new_text=[]\n",
        "\n",
        "    for word in text:\n",
        "      if word in contractions:\n",
        "        new_text.append(contractions[word])\n",
        "    \n",
        "      else:\n",
        "        new_text.append(word)\n",
        "        text=\" \".join(new_text)\n",
        "        text=re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "        text = re.sub(r'\\<a href', ' ', text)\n",
        "        text = re.sub(r'&amp;', '', text)\n",
        "        text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
        "        text = re.sub(r'<br />', ' ', text)\n",
        "        text = re.sub(r'\\'', ' ', text)\n",
        "            \n",
        "    if remove_stopwords:\n",
        "      text=text.split()\n",
        "      stops=set(stopwords.words(\"english\"))\n",
        "      text=[w for w in text if not w in stops]\n",
        "      text= \" \".join(text)\n",
        "\n",
        "  return text"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHQGzc61JufM",
        "outputId": "72c2409b-80c1-41ef-9c1c-15b8c8179512"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfqXrCcOJ6sE",
        "outputId": "0cbcafa5-bdcb-4fb4-ee13-e1d6d55efe74"
      },
      "source": [
        "# Clean the summaries and texts\n",
        "clean_summaries = []\n",
        "for summary in reviews.Summary:\n",
        "  clean_summaries.append(clean_text(summary, remove_stopwords=False))\n",
        "  print(\"Summaries are complete.\")\n",
        "clean_texts = []\n",
        "for text in reviews.Text:\n",
        "  clean_texts.append(clean_text(text))\n",
        "  print(\"Texts are complete.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Summaries are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n",
            "Texts are complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMbeDP1N592C"
      },
      "source": [
        "stories = list()\n",
        "for i, text in enumerate(clean_texts):\n",
        "        stories.append({'story': text, 'highlights': clean_summaries[i]})"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZBvbsop3lA7"
      },
      "source": [
        "Now we define our hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdUE7g0N3TcT"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 10\n",
        "latent_dim = 256\n",
        "num_samples = 10000"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6d1ltrt3uVh"
      },
      "source": [
        "##Now we vectorize the data##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaGB1fg63tVr",
        "outputId": "d9b2f6b8-8274-4a39-fac3-3900b5797868"
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "for story in stories:\n",
        "    input_text = story['story']\n",
        "    for highlight in story['highlights']:\n",
        "        target_text = highlight\n",
        "\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 200\n",
            "Number of unique input tokens: 40\n",
            "Number of unique output tokens: 21\n",
            "Max sequence length for inputs: 1460\n",
            "Max sequence length for outputs: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fungdqgi6DD2"
      },
      "source": [
        "##Creating encoder and decoder##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnck-V9D6RCO"
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnE4UxRu6m-y"
      },
      "source": [
        "**Define an input sequence and process it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1Qa8jY46sT0"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxzOCPVG7CsQ"
      },
      "source": [
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Run training\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONpfpXPA7lwC"
      },
      "source": [
        "# Define sampling models\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim))\n",
        "decoder_state_input_c = Input(shape=(latent_dim))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJcLVNYL7s88"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGJMRryW_Ddx",
        "outputId": "2091f2ec-fea9-4506-e8d9-d98bf5b906bc"
      },
      "source": [
        "for seq_index in range(100):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story c lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: got wild hair taffy ordered five pound bag taffy enjoyable many flavors watermelon root beer melon peppermint grape etc complaint bit much red black licorice flavored pieces particular favorites kids husband lasted two weeks would recommend brand taffy delightful treat\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: saltwater taffy great flavors soft chewy candy individually wrapped well none candies stuck together happen expensive version fralinger would highly recommend candy served beach themed party everyone loved\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: taffy good soft chewy flavors amazing would definitely recommend buying satisfying\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: right mostly sprouting cats eat grass love rotate around wheatgrass rye\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: healthy dog food good digestion also good small puppies dog eats required amount every feeding\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: know cactus tequila unique combination ingredients flavour hot sauce makes one kind picked bottle trip brought back home us totally blown away realized simply could find anywhere city bummed <br ><br >now magic internet case sauce ecstatic <br ><br >if love hot sauce mean really love hot sauce want sauce tastelessly burns throat grab bottle tequila picante gourmet de inclan realize taste never want use sauce <br ><br >thank personal incredible service\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: one boys needed lose weight put food floor chubby guy protein rich product food higher skinny boy jump higher food sits going stale really go food chubby boy losing ounce week\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: cats happily eating felidae platinum two years got new bag shape food different tried new food first put bowls bowls sit full kitties touch food noticed similar reviews related formula changes past unfortunately need find new food cats eat\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: good flavor came securely packed fresh delicious love twizzlers\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: strawberry twizzlers guilty pleasure yummy six pounds around son\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: daughter loves twizzlers shipment six pounds really hit spot exactly would expect six packages strawberry twizzlers\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: love eating good watching tv looking movies sweet like transfer zip lock baggie stay fresh take time eating\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: satisfied twizzler purchase shared others enjoyed definitely ordering\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: twizzlers strawberry childhood favorite candy made lancaster pennsylvania candies inc one oldest confectionery firms united states subsidiary hershey company company established 1845 young smylie also make apple licorice twists green color blue raspberry licorice twists like all<br ><br >i keep dry cool place recommended put fridge according guinness book records longest licorice twist ever made measured 1 200 feet 370 weighted 100 pounds 45 kg made candies inc record breaking twist became guinness world record july 19 1998 product kosher thank\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: candy delivered fast purchased reasonable price home bound unable get store perfect\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: husband twizzlers addict bought many times amazon government employees living overseas cannot get country assigned always fresh tasty packed well arrive timely manner\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: bought husband currently overseas loves apparently staff likes also <br >there generous amounts twizzlers 16 ounce bag well worth price\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: remember buying candy kid quality dropped years still superb product disappointed\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: love candy weight watchers cut back still craving\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: lived us 7 yrs miss twizzlers go back visit someone visits always stock say yum <br >sell mexico faithful buyer often able buy right\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: product received advertised <br ><br >\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: candy red flavor plan chewy would never buy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: glad amazon carried batteries hard time finding elsewhere unique size need garage door opener <br >great deal price\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: got mum diabetic needs watch sugar intake father simply chooses limit unnecessary sugar intake one sweet tooth loved toffees would never guess sugar free great eat pretty much guilt free impressed ordered w dark chocolate take office eat instead snacking sugary sweets <br >these excellent\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: know cactus tequila unique combination ingredients flavour hot sauce makes one kind picked bottle trip brought back home us totally blown away realized simply could find anywhere city bummed <br ><br >now magic internet case sauce ecstatic <br ><br >if love hot sauce mean really love hot sauce want sauce tastelessly burns throat grab bottle tequila picante gourmet de inclan realize taste never want use sauce <br ><br >thank personal incredible service\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: never huge coffee fan however mother purchased little machine talked trying latte macciato coffee shop better one like products usually non coffee drinker <br >the little dolche guesto machine super easy use prepares really good coffee latte cappuccino etc less minute water heated would recommend dolce gusto anyone good price getting one\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: offer great price great taste thanks amazon selling product <br ><br >staral\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: mccann instant oatmeal great must oatmeal scrape together two three minutes prepare escaping fact however even best instant oatmeal nowhere near good even store brand oatmeal requiring stovetop preparation still mccann good gets instant oatmeal even better organic natural brands tried varieties mccann variety pack taste good prepared microwave adding boiling water convenient extreme time issue <br ><br >mccann use actual cane sugar instead high fructose corn syrup helped decide buy product real sugar tastes better harmful stuff one thing like though mccann use thickeners oats plus water plus heat make creamy tasty oatmeal without need guar gum convenience product maybe guar gum sitting bowl instant mccann becomes thick gluey\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: good instant oatmeal best oatmeal brand uses cane sugar instead high fructouse corn syrup better sweetness doctors say form sugar better great cold morning time make mccann steel cut oats apple cinnamon best maple brown sugar regular good plus require doctoring actually tell three flavors apart\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: instant oatmeal become soggy minute water hits bowl mccann instant oatmeal holds texture excellent flavor good time mccann regular oat meal excellent may take bit longer prepare time morning best instant brand ever eaten close second non instant variety <br ><br >mccann instant irish oatmeal variety pack regular apples cinnamon maple brown sugar 10 count boxes pack 6\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: mccann instant irish oatmeal variety pack regular apples cinnamon maple brown sugar 10 count boxes pack 6 <br ><br >i fan mccann steel cut oats thought give instant variety try found hardy meal sweet great folks like post bariatric surgery need food palatable easily digestible fiber make bloat\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: us celiac disease product lifesaver could better getting almost half price grocery health food store love mccann instant oatmeal flavors <br ><br >thanks <br >abby\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: else need know oatmeal instant make half cup low fat milk add raisins nuke 90 seconds expensive kroger store brand oatmeal maybe little tastier better texture something still oatmeal mmm convenient\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: visiting friend nate morning coffee came storage room packet mccanns instant irish oatmeal suggested try use stash sometimes nate dose give chance say ended trying apple cinn found tastefull made water powdered milk goes good j coffee slice toast ready take world day least jerry reith\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: ordered wife reccomended daughter almost every morning likes flavors happy happy <br >\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: variety packs taste great <br ><br >i every morning 0 30 cents per meal understand everyone earth buying stuff <br ><br >maple brown sugar terrific followed apples cinnamon followed regular get tired ole thing taste great <br ><br >i boil water small pot empty packet 2 bowl pour boiling water watch expand 2x size <br ><br >taste really good takes minutes prepare <br ><br >not sure everyone earth convenient healthy quick excellent quality extremely cheap\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: mccann makes oatmeal every oatmeal connoisseur whether one likes raw pellet state cooks half hour sloth addled instant done microwave three minutes good sure beauty instant variety available different flavors well regular <br > variety pack allows different tastes explored well giving chance experience difference mccann well known oatmeals personally like mccann cooks thicker body top brand america apples cinnamon though tends little liquidy may want experiment amount water add 1300watt microwave oatmeal cooks one minute twenty seven seconds also watch get handle much time water use <br > bad thing consider bad thing offering buy lot shall end six ten count boxes good whole family oatmeal eaters single person alone well love oatmeal\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: mccann oatmeal every morning ordering amazon able save almost 3 00 per box <br >it great product tastes great healthy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: mccann oatmeal good quality choice favorite apples cinnamon find none overly sugary good hot breakfast 2 minutes excellent\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: really like mccann steel cut oats find cook often <br >this tastes much better grocery store brands convenient <br >anything keeps eating oatmeal regularly good thing\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: seems little wholesome supermarket brands somewhat mushy quite much flavor either pass muster kids probably buy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: good oatmeal like apple cinnamon best though would follow directions package since always comes soupy taste could since like oatmeal really thick add milk top\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: flavors good however see differce oaker oats brand mushy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: really like maple brown sugar flavor regular fine brown sugar added apples cinnamon flavor ok quick easy satisfying breakfast order brand variety get maple brown sugar\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: stuff buy big box stores nothing healthy carbs sugars save money get something least taste\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: oatmeal good mushy soft like quaker oats way go\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: got free package bottle bloody mary mix bought seller advertising worked lol tried shared 2 buddies loved im buy noticed reviews yet well hot burn mouth forever hot nice temp perfect us\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: stock last time looked go vermont country store weston find along jaw harp cranberry horseradish sauce fartless black bean salsa apple cider jelly newton cradle art motion staple vermont maple syrup <br ><br >back ass kickin peanuts hot activate perspiration glands behind ears arms requires beverage advertised glass cold milk box kleenex since make nose run look like ordinary peanuts already giving ideas work suspect people hitting goodies absence especially colleague greg going take work earliest opportunity empty contents ordinary planters peanuts see whose crying whose nose running return <br ><br >the shaken ensure spices evenly distributed important wash hands consumption touch eyes <br ><br >you go nuts ass kickin peanuts <br ><br >p sharing peanuts deliberately probably give greg jaw harp christmas shall insulted\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: used spicy foods south texas spicy doubt much habanero used could take notch two\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: roast home stove top popcorn popper outside course beans coffee bean direct green mexican altura seem well suited method first second cracks distinct roasted beans medium slightly dark great results every time aroma strong persistent taste smooth velvety yet lively\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: roast large cast iron pan grill 1 3 bag time smell wonderful roasted beans taste delicious importantly coffee smooth bitter aftertaste numerous occasions send roasted beans home friends like much\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: deal awesome arrived halloween indicated enough satisfy trick treaters love quality product much less expensive local store candy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: chocolate say great variety everything family loves family six goes fast perfect variety kit kat reeses take five\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: great product nice combination chocolates perfect size bags plenty shipped promptly kids neighborhood liked candies\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: halloween sent bag daughters class share chocolate fresh enjoyed many\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: watch prices assortment good get gold box purchase price was<br > 3 4 less target\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: bag candy online pretty expensive cheaper order compete grocery stores good combination favorite candy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: arrived 6 days stale could eat 6 bags\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: used endurolyte product several years pill powder form long desert rides dirt bike always found camelbak water heavily laced endurolyte powder overly tasty quite effective never got cramp several hundred mile rides desert racing buggy camelbaks always laced powder fizz great product firstly hammer endurolyte product great endurance athlete world use products second convenient handly tablets dissovle fizz third tastes great imagine getting nice cool drink body starving hydration electrolytes rather getting salty taste get refreshing lemon lime mango camelbaks always get fizz also drop tablet bottled water whenever exercise nice flavored water chock full electrolytes cannot recommend product hammer product highly enough\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: product serves well source electrolytes long run bike ride <br >i tried flavors really like grapefruit flavor taste actually like slight carbonation <br >i use hammer products really like whole product line\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: stuff really works preventing cramping middle latter stages rides pop 1 water bottle set flavor fine goes easy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: us low carb diet little tablets thing <br ><br >two years ago started cycling many years heart arrhythmia longer rides high heat drinking plain water little research thought electrolytes might issue gatorade option loaded carbohydrates looked around low carb alternative zero carb sports drinks help one day ran across bike shop tried tube voila problem solved <br ><br >i shared two friends particular whose problems leg cramps resolved using <br ><br >these guys got right superbly formulated simply work\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: purchased mango flavor take like mango hint sweetness unfortunately hint aftertaste almost like licorice consuming various sports nutrition products decades familiar come like taste products tried mango flavor one least appealing tasted terrible bad enough notice bad taste every sip take\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: impulsive like 6 ok get wrong quality babies good complaints retrospect price little ridiculous esp add shipping\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: sooooo deliscious bad ate em fast gained 2 pds fault\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: albanese gummi bears rings good tasty high quality bears even little faces local candy store type gummi stuff bears rings snakes balls worms whatever 10 lb twin packs 4 5 5 pound bags screaming deal far concerned probably 50 pounds deep friggin things consumed\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: grape gummy bears hard find area fact pretty much anyone talk grape gummy bears think lying bought 10lbs bears little bit bigger brands kind sour kick nothing strong love grape flavored candy soda pretty good another company makes grape gummy bears little bit better opinion well worth price like use gummy bears home made popsicles flavored sports drink salt sports drink makes softer popsicles gummy bears awesome frozen delicious\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: ordered two two raspberry latice tarts directly fantasicakes website dinner party hosting arrived fresh intact good size froze half later use pastry lover best ever tasted pastry soft jam really good taste great gone time guests really impressed\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: buyer beware please sweetener everybody maltitol alcohol sugar undigestible body know short time consuming one unsuspecting many cannot digest extreme intestinal bloating cramping massive amounts gas person experience nausea diarrhea headaches also experienced learned lesson hard way years ago fell love sugar free chocolates suzanne sommers used sell thought found sugar free chocolate nirvana first taste bliss short lived terrible side effects maltitol kicked discomfort unlike anything ever felt blew like balloon painful abdominal cramping symptoms passed unpleasant though hard believe low calorie sweetener could culprit symptoms gone stopped eating chocolate hunch something maltitol unfortunately confirmed year later purchased delicious sugar free popcorn local market taste amazing looking label wondering could possibly make yummy new sugarfree treat taste good heart sank followed little asterisk next sugarfree sweetener bottom label read maltitol tiny little letters thank goodness eaten little still ended side effects much shorter duration people use maltitol heart content others like bad reaction case like maltitol\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: okay would go way buy\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: tea flavor whole brunch artifial flavors returnable wasted 20 bucks\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: looked like perfect snack trail mix unfortunately arrived solid mass melted chocolate left pantry days opened room temperature still gooey fridge breaking hunks ever since taste good chocolate grainy melting solidifying order online see store would pick\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: taste really good purchasing different brand similar taste texture agree reviewer regarding ordering summer insulating packaging ice packs melt warm weather like chocolate food items order cold weather buy enough last\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: taste great berries melted may order winter order cold weather enjoy flavor\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: know cannot make tea good granted south know never enjoyed tea sweet without sweet tastes crisp\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: peppermint stick delicious fun eat dad got one christmas remembered similar one little girl 30 love\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: great gift ages purchased giant canes recipients loved much kept would eat\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: know product title says molecular gastronomy let scare looking food science something earth use make coffee creamer <br ><br >i coffee blonde sweet flavored creamers full bad kinds fat honestly hate use manufactured food items really think good body hand hate using cold milk cream like hot coffee <br ><br >i stumbled across amazon one day got idea making creamer also bought low fat non instant milk powder regular milk powder non instant lowfat milk little sweeter tastes fresher regular instant low fat milk dissolve good cold water problem hot coffee play ratios would heavy cream made coffee rich also think powder expensive use like mixing 1 3 together <br ><br >for flavoring bough cocoa bean powder vanilla bean powder caster superfine sugar mix small batches along spices like cinnamon nutmeg make flavored creamers wanted could use fake sweetner powder instead make small amounts store jelly canning jars also use little food chopper food processor blend everything sugar heavier sinks bottom let settle bit opening top though <br ><br >this stuff tastes way better storebought creamers fun experiment come flavors going try using essential oils next see get good chocolate orange mix <br ><br >all ingredients mentioned online take time experiment maybe use low fat milk add flavorings also would make great housewarming host ess gifts <br ><br >i sure molecular people able tell sure experiment cooking main reason bought make creamer worked great\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: dogs like flavors tried dog food reason itching increased tried lamb rice itchy dogs giving limited ingredient dog food try help duck sweet potato cut itching significantly tried lamb rice started itching like natural balance quality ingredients\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: awesome dog food however given boston severe reactions food ingredients itching increased violent jumping bed night scratching soon changed different formula scratching stopped glad natural balance choices guess try find best pet\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: three dogs love food bought specifically one dogs food allergies works great hot spots tummy problems <br >i love ships right door free shipping\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: dog ton allergies environmental food prescription dog food tested see allergies got test back learned allergic something prescription brand finally found dog food done well still environmental triggers happy finally eat something know cause pain\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: shepherd collie mix ibs vet recommended limited ingredient food really helped symptoms likes always buy amazon 10 cheaper free shipping\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: natural balance dry dog food lamb meal brown rice recipe wonders jack russell awful food allergy food last hope last food could find something allergic problem eating dry normally mix natural balance dry lamb brown rice natural balance wet lamb brown rice seems like better started feeding dog bichon loves dog allergy stomach issue want dog eat better food see difference pet\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: great food love idea one food ages breeds Ã®t real convenience well really good product 3 dogs eat less almost gas poop regular perfect consistency else mom ask\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: standard poodle pomeranian wonderful food switched different food due price couple times end going right back natural balance\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: great dog food dog severs allergies brand one feed\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: food great ages dogs 3 year old puppy soft hardly ever get sick food good especially amazon prime shipping\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: golden retriever one picky dogs ever met experimenting various types food found loves natural balance really like natural balance fact multiple flavors dry wet varieties mix dry food little wet food golden loves furthermore like mixing flavors time think meal day day might get little boring figured tend stay away fish type though smells <br ><br >additionally started purchasing amazon petco wet food box couple cans came home surprise realized could save 20 time bought dog food buy amazon <br ><br >all definitely recommend give stamp approval natural balance dog food never eaten dog seems love\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: food get pet store delivered door price slightly less\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: pleased natural balance dog food dogs issues dog foods past someone recommend natural balance grain free since possible allergic grains since switching issues also helpful different kibble size larger smaller sized dogs\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: 1 1 2 year old basenji jack russell mix loves dog food noticeably healthier energetic since switched standard dog foods earlier year despite higher cost natural dog foods find eats significantly less natural balance dog foods still stays happy full normal dog foods would eat 3 cups dog food day recommended serving size whereas eats 1 cup 1 1 2 cup natural balance dog food day take account actually getting bang buck natural dog foods since buy much last long normal dog foods healthier happier dog boot add fact get free 2 day shipping amazon prime sold\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: pup experienced allergies forms hotspots itching dog foods cheap buy anywhere food crazy preservatives cause health problems pets food works wonders reducing allergies dog loves food <br >this message ramsey frankenstein approved\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: english bulldog skin allergies summer got age 3 vet recommended wean food previous owner gave iams lamb rice onto new kind second one tried working ever since dogs need limited diet sensitive additives proteins commonly found commercial dog food like chicken beef\n",
            "Decoded sentence:  \n",
            "\n",
            "-\n",
            "Input sentence: fed golden retriever hated would eat gave terrible diarrhea buying also super expensive\n",
            "Decoded sentence:  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}